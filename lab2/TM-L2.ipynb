{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2: Text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text classification is the task of sorting text documents into predefined classes. The concrete problem you will be working on in this lab is the classification of texts with respect to their political affiliation. The specific texts you are going to classify are speeches held in the [Riksdag](https://www.riksdagen.se/en/), the Swedish national legislature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data for this lab comes from [The Riksdag’s Open Data](https://data.riksdagen.se/in-english/). We have tokenized the speeches and put them into two compressed [JSON](https://en.wikipedia.org/wiki/JSON) files:\n",
    "\n",
    "* `speeches-201718.json.bz2` (speeches from the 2017/2018 parliamentary session)\n",
    "* `speeches-201819.json.bz2` (ditto, from the 2018/2019 session)\n",
    "\n",
    "We start by loading these files into two separate data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bz2\n",
    "\n",
    "with bz2.open(\"speeches-201718.json.bz2\") as source:\n",
    "    speeches_201718 = pd.read_json(source)\n",
    "\n",
    "with bz2.open(\"speeches-201819.json.bz2\") as source:\n",
    "    speeches_201819 = pd.read_json(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you inspect the two data frames, you can see that there are three labelled columns: `id` (the official speech ID), `words` (the space-separated words of the speech), and `party` (the party of the speaker, represented by its customary abbreviation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>words</th>\n",
       "      <th>party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H5-002-004</td>\n",
       "      <td>eders majestäter eders kungliga högheter herr ...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H5-003-001</td>\n",
       "      <td>aktuell debatt om situationen för ensamkommand...</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H5-003-002</td>\n",
       "      <td>herr talman och ledamöter jag vill börja med a...</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H5-003-003</td>\n",
       "      <td>herr talman åhörare den här debatten handlar a...</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H5-003-004</td>\n",
       "      <td>herr talman ansvar och rättssäkerhet är två or...</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                              words party\n",
       "0  H5-002-004  eders majestäter eders kungliga högheter herr ...     S\n",
       "1  H5-003-001  aktuell debatt om situationen för ensamkommand...     V\n",
       "2  H5-003-002  herr talman och ledamöter jag vill börja med a...     S\n",
       "3  H5-003-003  herr talman åhörare den här debatten handlar a...     M\n",
       "4  H5-003-004  herr talman ansvar och rättssäkerhet är två or...    SD"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_201718.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the lab, we will be using the speeches from 2017/2018 as our training data, and the speeches from 2018/2019 as our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = speeches_201718, speeches_201819"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For later reference, we store the sorted list of party abbreviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'KD', 'L', 'M', 'MP', 'S', 'SD', 'V']\n"
     ]
    }
   ],
   "source": [
    "parties = sorted(training_data[\"party\"].unique())\n",
    "print(parties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first task is to get to know the data better by plotting a simple visualization.\n",
    "\n",
    "If you are not familiar with the Swedish political system and the parties represented in the Riksdag in particular, then we suggest that you have a look at the Wikipedia article about the [2018 Swedish general election](https://en.wikipedia.org/wiki/2018_Swedish_general_election).\n",
    "\n",
    "For the lab, we ask you to compare the two data frames with respect to the distribution of the speeches over the different parties. Write code to generate two bar plots that visualize this information, one for the 2017/2018 speeches and one for the 2018/2019 speeches. Inspect the two plots, and compare them\n",
    "\n",
    "* to each other\n",
    "* to the results of the 2014 and the 2018 general elections\n",
    "\n",
    "Summarize your observations in a short text in the cell below.\n",
    "\n",
    "**Tip:** If you need help with creating bar plots, [Bar Plot using Pandas](https://dfrieds.com/data-visualizations/bar-plot-python-pandas) provides a useful tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "#% matplotlib inline\n",
    "\n",
    "\n",
    "speeches_201718['party'].value_counts().plot(kind='bar');\n",
    "plt.title(\"Distribution of Speeches from the Parties in 2017-2018\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S     0.298557\n",
       "M     0.177003\n",
       "SD    0.114126\n",
       "V     0.102283\n",
       "KD    0.088394\n",
       "MP    0.087102\n",
       "C     0.072244\n",
       "L     0.060293\n",
       "Name: party, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_201819_procent = speeches_201819['party'].value_counts()/sum(speeches_201819['party'].value_counts())\n",
    "speeches_201819_procent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S     0.345216\n",
       "M     0.192012\n",
       "MP    0.119987\n",
       "SD    0.081828\n",
       "V     0.072430\n",
       "C     0.070080\n",
       "KD    0.060196\n",
       "L     0.058252\n",
       "Name: party, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_201718_procent = speeches_201718['party'].value_counts()/sum(speeches_201718['party'].value_counts())\n",
    "speeches_201718_procent                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "voteResults2014 = [31, 23.3, 6.9, 12.9, 5.7, 6.1, 4.6, 5.4]\n",
    "voteResults2018 = [28.3, 19.8, 4.4, 17.5, 8, 8.6, 6.3, 5.5]\n",
    "\n",
    "speeches_in_procent2018 = [30,18,9,11,10,7,9,6]\n",
    "Speeches_in_procent2017 = [34,19,12,8,7,7,6,5]\n",
    "\n",
    "partyList = ['S', 'M', 'MP', 'SD', 'V', 'C', 'KD', 'L']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAeIElEQVR4nO3deXSV1fn28e/NIChQKhCGigIqVaxAhDC4qJbhJyjVIkqlqQNUNLaFClqraO0sFl2oFPRV05dWaquBV1QooqUi1EIdCBiQGbGxBBEDihAt8/3+cQ75JZAJkuecfcj1WSsr5+zzDHfCWVzZz7PP3ubuiIiIhKZOsgsQEREpiwJKRESCpIASEZEgKaBERCRICigREQlSvWQXUBUtWrTw9u3bJ7sMERGJwLJly7a7e9qR7SkRUO3btyc3NzfZZYiISATM7IOy2iO7xGdmDc3sbTNbYWarzexX8fanzOzfZpYX/0qPqgYREUldUfag9gL93b3IzOoDi83s5fhrP3H35yI8t4iIpLjIAspjU1QUxZ/Wj39p2goREamSSO9BmVldYBlwNvCYu79lZj8AJpjZz4EFwHh331vGvllAFsAZZ5wRZZkikiT79++noKCAPXv2JLsUSYCGDRvStm1b6tevX6XtLRFz8ZnZl4EXgB8BO4CPgJOAbGCTu/+6ov0zMjJcgyRETjz//ve/adKkCc2bN8fMkl2ORMjd2bFjB7t376ZDhw6lXjOzZe6eceQ+CfkclLvvBBYCl7r7Vo/ZC/wR6JmIGkQkPHv27FE41RJmRvPmzY+ptxzlKL60eM8JMzsZuARYZ2Zt4m0GXAmsiqoGEQmfwqn2ONZ/6yjvQbUBpsfvQ9UBZrr7XDN7zczSAAPygO9HWIOIiKSoKEfxrQQuKKO9f1TnFJHUlnHUXYjqqezWdb9+/Rg/fjyDBg0qbps8eTLr16/n8ccfL3Of/Px8/vWvf/Hd7363Jks9Lvn5+Vx++eWsWrWKvLw8PvzwQwYPHlylfTdv3swNN9zAtm3bMDOysrIYO3YsAJ988gnDhw8nPz+f9u3bM3PmTE499VTWrVvH9773PZYvX86ECRO44447Sh3z4MGDZGRkcNpppzF37txq/3yai09Eaq3MzExycnJKteXk5JCZmVnuPvn5+TzzzDPHfU5359ChQ8e9f3ny8vKYN29elbevV68eDz30EGvWrOHNN9/kscceY82aNQBMnDiRAQMGsHHjRgYMGMDEiRMBaNasGVOmTDkqmA773e9+R6dOnar/wxyuscaOdILLyD7+P+1yszQCUSREw4YN495772Xfvn2cdNJJ5Ofn8+GHH3LRRRfh7tx55528/PLLmBn33nsvw4cPZ/z48axdu5b09HRGjBjBrbfeyvjx41m0aBF79+5l9OjR3HLLLaXOk5+fz6BBg+jVqxfLli1j3rx5rF+/nl/84hfs3buXs846iz/+8Y80btyY8ePHM2fOHOrVq8fAgQOZNGkSI0eO5PLLL2fYsGEANG7cmKKiouLj79u3j5///Of897//ZfHixdx99920bt26uEdkZrz++us0adKkeJ82bdrQpk0bAJo0aUKnTp3YsmUL5513HrNnz2bRokUAjBgxgr59+/LAAw/QsmVLWrZsyUsvvXTU77KgoICXXnqJn/70pzz88MM18u+jgBKRWqtZs2b07NmTl19+mSFDhpCTk8M111yDmTFr1izy8vJYsWIF27dvp0ePHlx88cVMnDiRSZMmFV/Cys7OpmnTpixdupS9e/fSp08fBg4ceNRQ6o0bNzJ9+nR69+7N9u3bue+++3j11Vdp1KgRDzzwAA8//DCjR4/mhRdeYN26dZgZO3furNLPcdJJJ/HrX/+a3NxcHn30UQCuuOIKHnvsMfr06UNRURENGzYsd//8/HzeeecdevXqBcC2bduKw6t169Zs27at0hrGjRvHgw8+yO7du6tUc1XoEp+I1GolL/OVvLy3ePFiMjMzqVu3Lq1ateIb3/gGS5cuPWr/+fPn86c//Yn09HR69erFjh072Lhx41HbtWvXjt69ewPw5ptvsmbNGvr06UN6ejrTp0/ngw8+oGnTpjRs2JBRo0bx/PPPc8oppxz3z9WnTx9uv/12pkyZws6dO6lXr+z+SFFREVdffTWTJ0/mS1/60lGvm1mlo+/mzp1Ly5Yt6d69+3HXWxb1oESkVhsyZAi33XYby5cv54svvjjm/2TdnalTp5YaaFGWRo0aldrnkksu4dlnnz1qu7fffpsFCxbw3HPP8eijj/Laa69Rr1694vtWhw4dYt++fZXWNX78eL75zW8yb948+vTpw9/+9jfOPffcUtvs37+fq6++mmuvvZarrrqquL1Vq1Zs3bqVNm3asHXrVlq2bFnhuZYsWcKcOXOYN28ee/bsYdeuXVx33XX8+c9/rrTOiqgHJSK1WuPGjenXrx833nhjqcERF110ETNmzODgwYMUFhby+uuv07NnT5o0aVLqMtagQYN4/PHH2b9/PwAbNmzg888/r/CcvXv3ZsmSJbz33nsAfP7552zYsIGioiI+++wzBg8ezCOPPMKKFSuA2JJDy5YtA2DOnDnF5yrpyLo2bdpE586dueuuu+jRowfr1q0rtb27M2rUKDp16sTtt99e6rVvfetbTJ8+HYDp06czZMiQCn+e3/72txQUFJCfn09OTg79+/evdjiBelAiEpBkzWiWmZnJ0KFDS43oGzp0KG+88QZdu3bFzHjwwQdp3bo1zZs3p27dunTt2pWRI0cyduxY8vPz6datG+5OWloaL774YoXnS0tL46mnniIzM5O9e2NTkd533300adKEIUOGsGfPHty9eLDBzTffzJAhQ+jatSuXXnppqd7YYf369WPixImkp6dz9913s3jxYhYuXEidOnX42te+xmWXXVZq+yVLlvD000/TuXNn0tNjqx7df//9DB48mPHjx3PNNdcwbdo02rVrx8yZMwH46KOPyMjIYNeuXdSpU4fJkyezZs2aMi8N1oSEzMVXXSHMxadRfCI1b+3atTU6LFnCV9a/eVLn4hMRETlWCigREQmSAkpERIKkgBIRkSApoEREJEgKKBERCZI+ByUiwajOxznKUpWPeEyYMIFnnnmGunXrUqdOHZ588sniOemi1L59e3Jzc2nRokWNHO+LL77g29/+Nps2baJu3bpcccUVxbOQ7927lxtuuIFly5bRvHlzZsyYQfv27dmxYwfDhg1j6dKljBw5sngev927d3PRRRcVH7ugoIDrrruOyZMn10itVaWAEpFa64033mDu3LksX76cBg0asH379ipNIxSqO+64g379+rFv3z4GDBjAyy+/zGWXXca0adM49dRTee+998jJyeGuu+5ixowZNGzYkN/85jesWrWKVav+d3HzJk2akJeXV/y8e/fupaZCShRd4hORWmvr1q20aNGCBg0aANCiRQu+8pWvALEezp133knnzp3p2bNn8bREhYWFXH311fTo0YMePXqwZMkSIDZd0Y033kjPnj254IILmD17NhBbxO+OO+7g/PPPp0uXLkydOrX4/FOnTqVbt2507ty5eCqi8o6zevVqevbsSXp6Ol26dDlqQtpTTjmFfv36AbHZzbt160ZBQQEAs2fPZsSIEUBsiZEFCxbg7jRq1Iivf/3rFc50vmHDBj7++ONSPapEUUCJSK01cOBANm/ezFe/+lV++MMf8o9//KPU602bNuXdd99lzJgxjBs3DoCxY8dy2223sXTpUmbNmsVNN90ExC4V9u/fn7fffpuFCxfyk5/8hM8//5zs7Gzy8/PJy8tj5cqVXHvttcXHb9GiBcuXL+cHP/gBkyZNqvA4TzzxBGPHjiUvL4/c3Fzatm1b7s+1c+dO/vrXvzJgwAAAtmzZwumnnw7EFips2rQpO3bsqNLvKCcnh+HDh1c6o3kUdIlPRGqtxo0bs2zZMv75z3+ycOFChg8fzsSJExk5ciRA8eSxmZmZ3HbbbQC8+uqrxSvPAuzatYuioiLmz5/PnDlzioNmz549/Oc//+HVV1/l+9//fvFyF82aNSve9/Bls+7du/P8888DlHucCy+8kAkTJlBQUMBVV11Fx44dy/yZDhw4QGZmJrfeeitnnnlmtX9HOTk5PP3009U+zvFQQIlIrVa3bl369u1L37596dy5M9OnTy8OqJK9hsOPDx06xJtvvnnUZTF3Z9asWZxzzjlVPvfhS4t169blwIEDFR6nU6dO9OrVi5deeonBgwfz5JNP0r9//6OOmZWVRceOHYt7fACnnXYamzdvpm3bthw4cIDPPvuM5s2bV1rfihUrOHDgQI2v81RVteYSX0ZG9b5E5MSzfv36Uvdy8vLyaNeuXfHzGTNmFH+/8MILgdhlwZL3kQ4PJhg0aBBTp07l8ATc77zzDgCXXHIJTz75ZHEAffLJJxXWVN5x3n//fc4880xuvfVWhgwZwsqVK4/a99577+Wzzz47arRdyeUznnvuOfr371+lS3bPPvtsqSVIEk09KBEJRqJn/i8qKuJHP/pR8YqzZ599NtnZ2cWvf/rpp3Tp0oUGDRoULy44ZcoURo8eTZcuXThw4AAXX3wxTzzxBD/72c8YN24cXbp04dChQ3To0IG5c+dy0003sWHDBrp06UL9+vW5+eabGTNmTLk1lXecmTNn8vTTT1O/fn1at27NPffcU2q/goICJkyYwLnnnku3bt0AGDNmDDfddBOjRo3i+uuv5+yzz6ZZs2allhVp3749u3btYt++fbz44ovMnz+f8847D4CZM2cyb968Gvt9H6tas9xGtXtBWVpuQ6SmhbzcRk1/TklitNyGiIikvMgCyswamtnbZrbCzFab2a/i7R3M7C0ze8/MZpjZSVHVICJyvPLz89V7SrIoe1B7gf7u3hVIBy41s97AA8Aj7n428CkwKsIaRCRwqXCbQWrGsf5bRxZQHlMUf1o//uVAf+C5ePt04MqoahCRsDVs2JAdO3YopGoBd2fHjh0VzlpxpEhH8ZlZXWAZcDbwGLAJ2OnuB+KbFACnlbNvFpAFcMYZZ0RZpogkSdu2bSkoKKCwsDDZpUgCNGzYsMIZMI4UaUC5+0Eg3cy+DLwAnHsM+2YD2RAbxRdNhSKSTPXr16dDhw7JLkMClZBRfO6+E1gIXAh82cwOB2NbYEsiahARkdQS5Si+tHjPCTM7GbgEWEssqIbFNxsBzI6qBhERSV1RXuJrA0yP34eqA8x097lmtgbIMbP7gHeAaRHWICIiKSqygHL3lcAFZbS/D/SM6rwiInJi0EwSIiISJAWUiIgESQElIiJBUkCJiEiQFFAiIhIkBZSIiARJASUiIkFSQImISJAUUCIiEiQFlIiIBEkBJSIiQVJAiYhIkBRQIiISJAWUiIgESQElIiJBUkCJiEiQFFAiIhIkBZSIiARJASUiIkFSQImISJAUUCIiEiQFlIiIBEkBJSIiQVJAiYhIkCILKDM73cwWmtkaM1ttZmPj7b80sy1mlhf/GhxVDSIikrrqRXjsA8CP3X25mTUBlpnZ3+OvPeLukyI8t4iIpLjIAsrdtwJb4493m9la4LSoziciIieWhNyDMrP2wAXAW/GmMWa20sz+YGanlrNPlpnlmlluYWFhIsoUEZGARB5QZtYYmAWMc/ddwOPAWUA6sR7WQ2Xt5+7Z7p7h7hlpaWlRlykiIoGJNKDMrD6xcPqLuz8P4O7b3P2gux8Cfg/0jLIGERFJTVGO4jNgGrDW3R8u0d6mxGZDgVVR1SAiIqkrylF8fYDrgXfNLC/edg+QaWbpgAP5wC0R1iAiIikqylF8iwEr46V5UZ1TREROHJpJQkREgqSAEhGRICmgREQkSAooEREJkgJKRESCFOUwc6mmjIzj3zc3t+bqEBFJBvWgREQkSAooEREJkgJKRESCpIASEZEgKaBERCRICigREQmSAkpERIKkgBIRkSApoEREJEgKKBERCZICSkREgqSAEhGRICmgREQkSAooEREJkgJKRESCpIASEZEgKaBERCRICigREQlSZAFlZqeb2UIzW2Nmq81sbLy9mZn93cw2xr+fGlUNIiKSuqLsQR0Afuzu5wG9gdFmdh4wHljg7h2BBfHnIiIipUQWUO6+1d2Xxx/vBtYCpwFDgOnxzaYDV0ZVg4iIpK6E3IMys/bABcBbQCt33xp/6SOgVTn7ZJlZrpnlFhYWJqJMEREJSOQBZWaNgVnAOHffVfI1d3fAy9rP3bPdPcPdM9LS0qIuU0REAhNpQJlZfWLh9Bd3fz7evM3M2sRfbwN8HGUNIiKSmqIcxWfANGCtuz9c4qU5wIj44xHA7KhqEBGR1FUvwmP3Aa4H3jWzvHjbPcBEYKaZjQI+AK6JsAYREUlRkQWUuy8GrJyXB0R1XhEROTFoJgkREQlSlJf4JIkysjOqtX9uVm4NVSIicnzUgxIRkSApoEREJEgKKBERCZICSkREgnRMAWVmvc3sFTNbZGaa5FVERCJT4Sg+M2vt7h+VaLodGErs801vAS9GWJuIiNRilQ0zf8LMlgMPuvseYCcwDDgE7KpwTxERkWqo8BKfu18JvAPMNbMbgHFAA6A5WsdJREQiVOk9KHf/KzAIaAq8AGxw9ynurkWaREQkMhUGlJl9y8wWAq8Aq4DhwBAzyzGzsxJRoIiI1E6V3YO6D+gJnAz8zd17Aj82s47ABOA7EdcnIiK1VGUB9RlwFXAKJRYWdPeNKJxERCRCld2DGkpsQEQ94LvRlyMiIhJTYQ/K3bcDUxNUi4iISDFNdSQiIkFSQImISJAUUCIiEiQFlIiIBEkBJSIiQVJAiYhIkBRQIiISJAWUiIgEKbKAMrM/mNnHZraqRNsvzWyLmeXFvwZHdX4REUltUfagngIuLaP9EXdPj3/Ni/D8IiKSwiILKHd/HfgkquOLiMiJLRn3oMaY2cr4JcBTy9vIzLLMLNfMcgsLtTaiiEhtk+iAehw4C0gHtgIPlbehu2e7e4a7Z6SlpSWqPhERCURCA8rdt7n7QXc/BPye2GKIIiIiR0loQJlZmxJPhxJbRl5EROQola2oe9zM7FmgL9DCzAqAXwB9zSwdcCAfuCWq84uISGqLLKDcPbOM5mlRnU9ERE4smklCRESCpIASEZEgKaBERCRICigREQmSAkpERIKkgBIRkSApoEREJEgKKBERCVJkH9QVCV1GRvX2z82tmTpEpGzqQYmISJAUUCIiEiQFlIiIBEkBJSIiQVJAiYhIkDSKT4KRkX38w+pyszSkTuREox6UiIgESQElIiJBUkCJiEiQFFAiIhIkBZSIiARJASUiIkFSQImISJAUUCIiEiQFlIiIBCmygDKzP5jZx2a2qkRbMzP7u5ltjH8/Narzi4hIaouyB/UUcOkRbeOBBe7eEVgQfy4iInKUyALK3V8HPjmieQgwPf54OnBlVOcXEZHUluh7UK3cfWv88UdAq/I2NLMsM8s1s9zCwsLEVCciIsFI2iAJd3fAK3g9290z3D0jLS0tgZWJiEgIEh1Q28ysDUD8+8cJPr+IiKSIRAfUHGBE/PEIYHaCzy8iIikiymHmzwJvAOeYWYGZjQImApeY2Ubgf+LPRUREjhLZirrunlnOSwOiOqeIiJw4NJOEiIgESQElIiJBUkCJiEiQFFAiIhIkBZSIiARJASUiIkFSQImISJAi+xyUyIkuIzujWvvnZuXWUCUiJyb1oEREJEgKKBERCZICSkREgqSAEhGRICmgREQkSAooEREJkoaZS43JqN6oa8iqkTKkAtUZGp+MYfEayl+7qQclIiJBUkCJiEiQFFAiIhIkBZSIiARJASUiIkHSKD4RiUxtG9mpUYc1Sz0oEREJknpQIimktvVIpHZTD0pERIKUlB6UmeUDu4GDwAF3r+7fhSIitVJ1e9W5Ad/2SuYlvn7uvj2J5xcRkYDpEp+IiAQpWT0oB+abmQNPunv2kRuYWRbxW7pnnHFGgssTEakdQp5AOFk9qK+7ezfgMmC0mV185Abunu3uGe6ekZaWlvgKRUQkqZLSg3L3LfHvH5vZC0BP4PVk1CIiUlK1Bh1oGH+NSngPyswamVmTw4+BgcCqRNchIiJhS0YPqhXwgpkdPv8z7v5KEuoQEZGAJTyg3P19oGuizysiIqlFw8xFRCRICigREQmSAkpERIKkgBIRkSApoEREJEgKKBERCZICSkREgqSAEhGRICmgREQkSAooEREJkgJKRESCpIASEZEgKaBERCRICigREQmSAkpERIKkgBIRkSApoEREJEgKKBERCZICSkREgqSAEhGRICmgREQkSAooEREJkgJKRESCpIASEZEgJSWgzOxSM1tvZu+Z2fhk1CAiImFLeECZWV3gMeAy4Dwg08zOS3QdIiIStmT0oHoC77n7++6+D8gBhiShDhERCZi5e2JPaDYMuNTdb4o/vx7o5e5jjtguC8iKPz0HWJ/QQo9NC2B7sos4RqlWc6rVC6lXc6rVC6lXc6rVC4mpuZ27px3ZWC/ikx43d88GspNdR1WYWa67ZyS7jmORajWnWr2QejWnWr2QejWnWr2Q3JqTcYlvC3B6iedt420iIiLFkhFQS4GOZtbBzE4CvgPMSUIdIiISsIRf4nP3A2Y2BvgbUBf4g7uvTnQdNSwlLkUeIdVqTrV6IfVqTrV6IfVqTrV6IYk1J3yQhIiISFVoJgkREQmSAkpERIKkgKomM/upma02s5VmlmdmvZJdU3nMzM3szyWe1zOzQjObm8y6SqqsRjMbGX+eZ2ZrzOzm5FVbXONR7wEzWxSfzmulma0zs0fN7MvJrvVIZrbQzAYd0TbOzB5PVk1VYWatzSzHzDaZ2TIzm2dmX012XYeZWVGJx4PNbIOZtTOzX5rZlvj7ZKOZPR/qTDolf4ZkUUBVg5ldCFwOdHP3LsD/AJuTW1WFPgfON7OT488vIbwh/lWpcYa7pwN9gfvNrFUC6yulkvfAtfG2LsBeYHZyqqzQs8RG0pb0nXh7kMzMgBeARe5+lrt3B+4GkvY+KI+ZDQCmAJe5+wfx5kfcPd3dOwIzgNfM7KgPqYoCqrraANvdfS+Au2939w+TXFNl5gHfjD/OJMz/iKpUo7t/DGwC2iWorrJU+h6IT+l1J3CGmXVNQo0VeQ74ZvwjH5hZe+ArwD+TWFNl+gH73f2Jww3uvsLdg6rZzC4Gfg9c7u6bytrG3WcA84HvJrK2VKGAqp75wOnx7vv/MbNvJLugKsgBvmNmDYn9Zf9WkuspS5VqNLMzgTOB9xJY25Gq9B5w94PACuDchFZXCXf/BHib2OTNEOs9zfSwh/eeDyxLdhGVaAC8CFzp7usq2XY5gb0vQqGAqgZ3LwK6E5szsBCYYWYjk1pUJdx9JdCeWM9kXnKrKVsVahxuZnnEela3xP+TTYpjfA9Youo6RiUv8wV9eS+F7Af+BYyqwrahvi+SLti5+FJF/C/jRcAiM3sXGAE8lcyaqmAOMInYPZzmyS2lXBXVOOPIyYWTqZz3QCnxZWY6A2sTW12VzAYeMbNuwCnuHnrvZDUwLNlFVOIQcA2wwMzucff7K9j2AiA3MWWlFvWgqsHMzjGzjiWa0oEPyts+IH8AfuXu7ya7kAqkQo1Veg+YWX3gt8DmeO8wKPFe4EJiv/NU6D29BjSIr3gAgJl1MbOLkljTUdz9C2L3Uq81szJ7UmZ2NTCQ1Pi9J5x6UNXTGJgaHz58gNi9kKyKd0k+dy8gNrIoWKlQY1x574HngL+Y2V5i9yNeJex1z54lNjLuyBF9wXF3N7OhwGQzuwvYA+QD45JaWBnc/RMzuxR43cwK4823mdl1QCNgFdDf3QvLPUjynGJmBSWeP+zuDyeyAE11JCIiQdIlPhERCZICSkREgqSAEhGRICmgREQkSAooEREJkgJKJGJmdjA+e/UqM/t/ZnbKMe4/7lj3ETkRKKBEovff+OzV5wP7gO9Xdcf4DBTjAAWU1DoKKJHE+idwNoCZvRhfy2j1EbMiFJnZQ2a2AvgpsdnFF8bXbrrRzCaX2PZmM3sk0T+ESCLog7oiETOzIndvbGb1gFnAK+7+uJk1i880cDKwFPiGu+8wMweGu/vM+P75QIa7bzezxsRnRXf3/Wb2L2IT5gY9JZTI8dBURyLROzk++zrEelDT4o9vjU/ZA3A60BHYARwkFmRHcfciM3sNuNzM1gL1FU5yolJAiUTvv/EVgIuZWV9iq+9e6O5fmNkioGH85T3xGdLL83+Be4B1wB9rvlyRMCigRJKjKfBpPJzOBXpXsO1uoAmwHcDd3zKz04FuxBZ0FDkhaZCESHK8AtSLX6abCLxZwbbZwCtmtrBE20xgibt/GmGNIkmlQRIiKcjM5gKPuPuCZNciEhX1oERSiJl92cw2ELuvpXCSE5p6UCIiEiT1oEREJEgKKBERCZICSkREgqSAEhGRICmgREQkSP8fZvlPh61cJ3YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_groups = 8\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    "\n",
    "rects1 = plt.bar(index, voteResults2014, bar_width,\n",
    "alpha=opacity,\n",
    "color='b',\n",
    "label='Vote results 2014')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, Speeches_in_procent2017, bar_width,\n",
    "alpha=opacity,\n",
    "color='g',\n",
    "label='Speeches 2017')\n",
    "\n",
    "plt.xlabel('Party')\n",
    "plt.ylabel('%')\n",
    "plt.title('')\n",
    "plt.xticks(index + bar_width, partyList)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Code inspired by https://pythonspot.com/matplotlib-bar-chart/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAdsUlEQVR4nO3de3SU1b3/8fdXEgGBUoEIKEJQqYIQIobbolIuh4scNaIUm+PPwhLFY6GClip6bO1plWIXCoV60LS0Uq2CP1GxeClCoR6oKAEiakBAjSWIGhDEcA98zx8ZsgIhFwgzs4d8XmtlZWbP88zznWRWPtnPs2dvc3dERERCc0a8CxARETkeBZSIiARJASUiIkFSQImISJAUUCIiEqSkeBdQHc2aNfPU1NR4lyEiIlGwatWqbe6ecmx7QgRUamoqOTk58S5DRESiwMw+PV67TvGJiEiQFFAiIhIkBZSIiAQpIa5Bicjp6eDBgxQUFLBv3754lyIxUK9ePVq1akVycnK1tldAiUjcFBQU0KhRI1JTUzGzeJcjUeTubN++nYKCAtq2bVutfXSKT0TiZt++fTRt2lThVAuYGU2bNj2h3nLUAsrM6pnZO2b2rpl9YGb/HWlva2Zvm9kmM5trZmdGqwYRCZ/CqfY40d91NHtQ+4F+7t4ZSAcGm1kP4GFgqrtfBOwARkWxBhERSVBRCygvURS5mxz5cqAf8HykfTZwbbRqEJHEkpFxar+q0rdvX/72t78d1TZt2jRuv/32CvfJz8/nmWeeqelLPSXy8/Pp2LEjALm5ubz66qvV3nfz5s307duXDh06cOmll/Lb3/629LGvvvqKAQMG0K5dOwYMGMCOHTsAWL9+PT179qRu3bpMmTLlqOebOnUql156KR07diQrK+uUDHyJ6jUoM6tjZrnAl8AbwEfATncvjmxSAJwXzRpERCqSlZXFnDlzjmqbM2cOWVlZFe5T04Bydw4fPnzS+1fkRAMqKSmJRx55hLy8PFasWMFjjz1GXl4eAJMnT6Z///5s3LiR/v37M3nyZACaNGnC9OnTmTBhwlHPtWXLFqZPn05OTg7vv/8+hw4dKvdzPRlRHcXn7oeAdDP7NvAicEl19zWz0cBogNatW0enwBOQkV2Nf8cqkDNa0zSJhGjYsGHcf//9HDhwgDPPPJP8/Hw+++wzrrjiCtydu+++m9deew0z4/777+eGG25g4sSJrFu3jvT0dEaMGMEdd9zBxIkTWbp0Kfv372fMmDHcdtttRx0nPz+fQYMG0b17d1atWsWrr77Khx9+yAMPPMD+/fu58MIL+dOf/kTDhg2ZOHEiL7/8MklJSQwcOJApU6YwcuRIrrrqKoYNGwZAw4YNKSoqKn3+AwcO8POf/5y9e/eybNky7r33Xlq0aMG4ceOAkms/b775Jo0aNSrdp2XLlrRs2RKARo0a0b59e7Zs2UKHDh2YP38+S5cuBWDEiBH06dOHhx9+mHPOOYdzzjmHV155pdzPsri4mL1795KcnMyePXs499xza/z7ickwc3ffaWZLgJ7At80sKdKLagVsqWCfbCAbICMjQ+vSi8gp16RJE7p168Zrr71GZmYmc+bMYfjw4ZgZ8+bNIzc3l3fffZdt27bRtWtXevfuzeTJk5kyZQoLFiwAIDs7m8aNG7Ny5Ur2799Pr169GDhwYLmh1Bs3bmT27Nn06NGDbdu28eCDD7Jo0SIaNGjAww8/zKOPPsqYMWN48cUXWb9+PWbGzp07q/U6zjzzTH75y1+Sk5PD7373OwCuvvpqHnvsMXr16kVRURH16tWrcP/8/HzWrFlD9+7dAfjiiy9Kw6tFixZ88cUXlR7/vPPOY8KECbRu3Zr69eszcOBABg4cWK3aKxPNUXwpkZ4TZlYfGACsA5YAwyKbjQDmR6sGEZGqlD3NV/b03rJly8jKyqJOnTo0b96c733ve6xcubLc/gsXLuTPf/4z6enpdO/ene3bt7Nx48Zy27Vp04YePXoAsGLFCvLy8ujVqxfp6enMnj2bTz/9lMaNG1OvXj1GjRrFCy+8wFlnnXXSr6tXr17cddddTJ8+nZ07d5KUdPz+SFFREddffz3Tpk3jW9/6VrnHzazK0Xc7duxg/vz5fPLJJ3z22Wfs3r2bp59++qRrPyKa16BaAkvMbC2wEnjD3RcA9wB3mdkmoCkwK4o1iIhUKjMzk8WLF7N69Wr27NnD5ZdffkL7uzszZswgNzeX3NxcPvnkk+P2Hho0aHDUPgMGDCjdJy8vj1mzZpGUlMQ777zDsGHDWLBgAYMHDwZKrhcduW51+PBhDhw4UGVdEydO5A9/+AN79+6lV69erF+/vtw2Bw8e5Prrr+fGG2/kuuuuK21v3rw5W7duBWDr1q2cc845lR5r0aJFtG3blpSUFJKTk7nuuuv45z//WWWNVYnmKL617n6Zu6e5e0d3/2Wk/WN37+buF7n79919f7RqEBGpSsOGDenbty8333zzUYMjrrjiCubOncuhQ4coLCzkzTffpFu3bjRq1IhvvvmmdLtBgwYxc+ZMDh48CMCGDRvYvXt3pcfs0aMHy5cvZ9OmTQDs3r2bDRs2UFRUxNdff82QIUOYOnUq7777LlCy5NCqVasAePnll0uPVdaxdX300Ud06tSJe+65h65du5YLKHdn1KhRtG/fnrvuuuuox6655hpmz54NwOzZs8nMzKz09bRu3ZoVK1awZ88e3J3FixfTvn37SvepDk11JCLBiNeyb1lZWQwdOvSokWdDhw7lrbfeonPnzpgZv/nNb2jRogVNmzalTp06dO7cmZEjRzJu3Djy8/Pp0qUL7k5KSgovvfRSpcdLSUnhySefJCsri/37S/5Hf/DBB2nUqBGZmZns27cPd+fRRx8F4NZbbyUzM5POnTszePDgo3pjR/Tt25fJkyeTnp7Ovffey7Jly1iyZAlnnHEGl156KVdeeeVR2y9fvpynnnqKTp06kZ6eDsCkSZMYMmQIEydOZPjw4cyaNYs2bdrw3HPPAfD555+TkZHBrl27OOOMM5g2bRp5eXl0796dYcOG0aVLF5KSkrjssssYPXr0yf9CIsw9/PEHGRkZHu8FCzWKT+TUW7du3Sn5T1sSx/F+52a2yt3L/ZHVXHwiIhIkBZSIiARJASUiIkFSQImISJAUUCIiEqRaM8y8OjMbV6rmIyZFROQE1JqAEpHw1eTjHMdTnY94PPTQQzzzzDPUqVOHM844gyeeeKJ0TrpoSk1NJScnh2bNmp2S59uzZw/f//73+eijj6hTpw5XX3116Szk+/fv54c//CGrVq2iadOmzJ07l9TUVLZv386wYcNYuXIlI0eOLJ3HD+DZZ59l0qRJmBnnnnsuTz/99Cmrtbp0ik9Eaq233nqLBQsWsHr1atauXcuiRYs4//zz413WSZswYQLr169nzZo1LF++nNdeew2AWbNmcfbZZ7Np0ybuvPNO7rnnHgDq1avHr371q3JrOxUXFzNu3DiWLFnC2rVrSUtLOyq8YkUBJSK11tatW2nWrBl169YFoFmzZqXLRKSmpnL33XfTqVMnunXrVjotUWFhIddffz1du3ala9euLF++HCiZrujmm2+mW7duXHbZZcyfXzIP9qFDh5gwYQIdO3YkLS2NGTNmlB5/xowZdOnShU6dOpVORVTR83zwwQd069aN9PR00tLSyk1Ie9ZZZ9G3b1+gZHbzLl26UFBQAMD8+fMZMWIEULLEyOLFi3F3GjRowHe/+91yM527O+7O7t27cXd27dp1SpbPOFEKKBGptQYOHMjmzZv5zne+w49+9CP+8Y9/HPV448aNee+99xg7dizjx48HYNy4cdx5552sXLmSefPmccsttwAlpwr79evHO++8w5IlS/jpT3/K7t27yc7OJj8/n9zcXNauXcuNN95Y+vzNmjVj9erV3H777aW9mIqe5/HHH2fcuHHk5uaSk5NDq1atKnxdO3fu5K9//Sv9+/cHShYUPNIzTEpKonHjxmzfvr3C/ZOTk5k5cyadOnXi3HPPJS8vj1GjRp3ET7hmFFAiUms1bNiQVatWkZ2dTUpKCjfccANPPvlk6eNHJo/NysrirbfeAkpm7h47dizp6elcc8017Nq1i6KiIhYuXFg6F16fPn3Yt28f//rXv1i0aBG33XZb6XIXTZo0KX3+IzOIX3755eTn5wNU+Dw9e/Zk0qRJPPzww3z66afUr1//uK+puLiYrKws7rjjDi644IKT+rkcPHiQmTNnsmbNGj777DPS0tL49a9/fVLPVRMaJCEitVqdOnXo06cPffr0oVOnTsyePZuRI0cCHLUO0pHbhw8fZsWKFcc9LTZv3jwuvvjiah/7yKnFOnXqUFxcXOnztG/fnu7du/PKK68wZMgQnnjiCfr161fuOUePHk27du1Ke3xQsqDg5s2badWqFcXFxXz99dc0bdq0wrpyc3MBuPDCCwEYPnx46YCLWFIPSkRqrQ8//PCoazm5ubm0adOm9P7cuXNLv/fs2RMoOS1Y9jrSkT/mgwYNYsaMGRyZgHvNmjUADBgwgCeeeKI0gL766qtKa6roeT7++GMuuOAC7rjjDjIzM1m7dm25fe+//36+/vprpk2bdlR72eUznn/+efr161fpIoTnnXceeXl5FBYWAvDGG2/EZVJf9aBEJBixnvm/qKiIH//4x6Urzl500UVkZ2eXPr5jxw7S0tKoW7cuzz77LADTp09nzJgxpKWlUVxcTO/evXn88cf52c9+xvjx40lLS+Pw4cO0bduWBQsWcMstt7BhwwbS0tJITk7m1ltvZezYsRXWVNHzPPfcczz11FMkJyfTokUL7rvvvqP2Kygo4KGHHuKSSy6hS5cuAIwdO5ZbbrmFUaNGcdNNN3HRRRfRpEmTo5YVSU1NZdeuXRw4cICXXnqJhQsX0qFDBx544AF69+5NcnIybdq0OerUZ6zUmuU2av5BXS23IXKqhbzcxqn+nJKU0HIbIiKS8HSKT0TkOI6MqpP4UQ9KROIqES4zyKlxor9rBZSIxE29evXYvn27QqoWcHe2b99ebnh+ZXSKT0TiplWrVhQUFJQOZ5bTW7169SqdAeNYCigRiZvk5GTatm0b7zIkUDrFJyIiQVJAiYhIkBRQIiISJAWUiIgESQElIiJBUkCJiEiQohZQZna+mS0xszwz+8DMxkXaf2FmW8wsN/I1JFo1iIhI4orm56CKgZ+4+2ozawSsMrM3Io9NdfcpUTy2iIgkuKgFlLtvBbZGbn9jZuuA86J1PBEROb3E5BqUmaUClwFvR5rGmtlaM/ujmZ1dwT6jzSzHzHI0DYqISO0T9YAys4bAPGC8u+8CZgIXAumU9LAeOd5+7p7t7hnunpGSkhLtMkVEJDBRDSgzS6YknP7i7i8AuPsX7n7I3Q8Dvwe6RbMGERFJTNEcxWfALGCduz9apr1lmc2GAu9HqwYREUlc0RzF1wu4CXjPzHIjbfcBWWaWDjiQD9wWxRpERCRBRXMU3zLAjvPQq9E6poiInD40k4SIiARJASUiIkFSQImISJAUUCIiEiQFlIiIBEkBJSIiQVJAiYhIkBRQIiISJAWUiIgESQElIiJBUkCJiEiQFFAiIhIkBZSIiARJASUiIkFSQImISJAUUCIiEiQFlIiIBEkBJSIiQVJAiYhIkBRQIiISJAWUiIgESQElIiJBUkCJiEiQFFAiIhIkBZSIiARJASUiIkFSQImISJAUUCIiEqSoBZSZnW9mS8wsz8w+MLNxkfYmZvaGmW2MfD87WjWIiEjiimYPqhj4ibt3AHoAY8ysAzARWOzu7YDFkfsiIiJHiVpAuftWd18duf0NsA44D8gEZkc2mw1cG60aREQkccXkGpSZpQKXAW8Dzd19a+Shz4HmFewz2sxyzCynsLAwFmWKiEhAoh5QZtYQmAeMd/ddZR9zdwf8ePu5e7a7Z7h7RkpKSrTLFBGRwCRF88nNLJmScPqLu78Qaf7CzFq6+1Yzawl8Gc0aEllGxsnvm5Nz6uoQEYmHaI7iM2AWsM7dHy3z0MvAiMjtEcD8aNUgIiKJK5o9qF7ATcB7ZpYbabsPmAw8Z2ajgE+B4VGsQUREElTUAsrdlwFWwcP9o3VcERE5PWgmCRERCZICSkREgqSAEhGRICmgREQkSAooEREJkgJKRESCpIASEZEgKaBERCRICigREQlSVCeLlfjJyK7BTLNAzmjNNisi8aUelIiIBEkBJSIiQVJAiYhIkHQNSmqtmiwICVoUUiTa1IMSEZEgKaBERCRICigREQmSAkpERIKkgBIRkSApoEREJEgKKBERCZICSkREgqSAEhGRICmgREQkSCcUUGbWw8xeN7OlZnZttIoSERGpdC4+M2vh7p+XaboLGAoY8DbwUhRrExGRWqyqyWIfN7PVwG/cfR+wExgGHAZ2Rbs4ERGpvSo9xefu1wJrgAVm9kNgPFAXaAroFJ+IiERNldeg3P2vwCCgMfAisMHdp7t7YbSLExGR2qvSgDKza8xsCfA68D5wA5BpZnPM7MIq9v2jmX1pZu+XafuFmW0xs9zI15BT8SJEROT0U9U1qAeBbkB94G/u3g34iZm1Ax4CflDJvk8CvwP+fEz7VHefcnLliohIbVFVQH0NXAecBXx5pNHdN1J5OOHub5pZag3rExGRWqqqa1BDKRkQkQT8xyk65lgzWxs5BXh2RRuZ2WgzyzGznMJCXe4SEaltqhrFt83dZ7j74+5+KoaVzwQuBNKBrcAjlRw7290z3D0jJSXlFBxaREQSSUynOnL3L9z9kLsfBn5PyfUtERGRcmIaUGbWsszdoZSMDBQRESmnqkESJ83MngX6AM3MrAB4AOhjZumAA/nAbdE6voiIJLaoBZS7Zx2neVa0jiciIqcXLbchIiJBUkCJiEiQFFAiIhIkBZSIiARJASUiIkFSQImISJAUUCIiEiQFlIiIBEkBJSIiQVJAiYhIkBRQIiISJAWUiIgESQElIiJBUkCJiEiQFFAiIhIkBZSIiARJASUiIkFSQImISJAUUCIiEiQFlIiIBEkBJSIiQVJAiYhIkBRQIiISJAWUiIgEKSneBYgkqozsjBrtnzM65xRVInJ6Ug9KRESCpIASEZEgKaBERCRIUQsoM/ujmX1pZu+XaWtiZm+Y2cbI97OjdXwREUls0exBPQkMPqZtIrDY3dsBiyP3RUREyolaQLn7m8BXxzRnArMjt2cD10br+CIikthiPcy8ubtvjdz+HGhe0YZmNhoYDdC6desYlCZy+qvJ0HgNi5dYi9sgCXd3wCt5PNvdM9w9IyUlJYaViYhICGIdUF+YWUuAyPcvY3x8ERFJELEOqJeBEZHbI4D5MT6+iIgkiGgOM38WeAu42MwKzGwUMBkYYGYbgX+L3BcRESknaoMk3D2rgof6R+uYIiJy+tBMEiIiEiQFlIiIBEnLbUgw9BkdSXRaguXUUg9KRESCpIASEZEg6RSfiERNRs3OeJGjM161mnpQIiISJAWUiIgESQElIiJB0jUokQRS02s6JQvYiCQG9aBERCRICigREQmSAkpERIKkgBIRkSApoEREJEgKKBERCZKGmYtIsDQ7eO2mHpSIiARJASUiIkFSQImISJAUUCIiEiQFlIiIBEmj+EREyqjRhLyajPeUUg9KRESCpB6UiEgtVpPPmkX7c2bqQYmISJAUUCIiEiQFlIiIBCku16DMLB/4BjgEFLt7TReyFhGplWo06hCCHnkYz0ESfd19WxyPLyIiAdMpPhERCVK8AsqBhWa2ysyO28E0s9FmlmNmOYWFhTEuT0RE4i1eAfVdd+8CXAmMMbPex27g7tnunuHuGSkpKbGvUERE4iouAeXuWyLfvwReBLrFow4REQlXzAPKzBqYWaMjt4GBwPuxrkNERMIWj1F8zYEXzezI8Z9x99fjUIeIiAQs5gHl7h8DnWN9XIm+0/nzGCISexpmLiIiQVJAiYhIkBRQIiISJAWUiIgESQElIiJBUkCJiEiQFFAiIhIkBZSIiARJASUiIkFSQImISJAUUCIiEiQFlIiIBEkBJSIiQVJAiYhIkBRQIiISJAWUiIgESQElIiJBUkCJiEiQFFAiIhIkBZSIiARJASUiIkFSQImISJAUUCIiEiQFlIiIBEkBJSIiQVJAiYhIkBRQIiISJAWUiIgESQElIiJBiktAmdlgM/vQzDaZ2cR41CAiImGLeUCZWR3gMeBKoAOQZWYdYl2HiIiELR49qG7AJnf/2N0PAHOAzDjUISIiATN3j+0BzYYBg939lsj9m4Du7j72mO1GA6Mjdy8GPoxpoSemGbAt3kWcoESrOdHqhcSrOdHqhcSrOdHqhdjU3MbdU45tTIryQU+au2cD2fGuozrMLMfdM+Jdx4lItJoTrV5IvJoTrV5IvJoTrV6Ib83xOMW3BTi/zP1WkTYREZFS8QiolUA7M2trZmcCPwBejkMdIiISsJif4nP3YjMbC/wNqAP80d0/iHUdp1hCnIo8RqLVnGj1QuLVnGj1QuLVnGj1QhxrjvkgCRERkerQTBIiIhIkBZSIiARJAVVDZvZfZvaBma01s1wz6x7vmipiZm5mT5e5n2RmhWa2IJ51lVVVjWY2MnI/18zyzOzW+FVbWmO594CZLY1M57XWzNab2e/M7NvxrvVYZrbEzAYd0zbezGbGq6bqMLMWZjbHzD4ys1Vm9qqZfSfedR1hZkVlbg8xsw1m1sbMfmFmWyLvk41m9kKoM+mUfQ3xooCqATPrCVwFdHH3NODfgM3xrapSu4GOZlY/cn8A4Q3xr06Nc909HegDTDKz5jGs7yhVvAdujLSlAfuB+fGpslLPUjKStqwfRNqDZGYGvAgsdfcL3f1y4F4gbu+DiphZf2A6cKW7fxppnuru6e7eDpgL/N3Myn1IVRRQNdUS2Obu+wHcfZu7fxbnmqryKvDvkdtZhPmHqFo1uvuXwEdAmxjVdTxVvgciU3rdDbQ2s85xqLEyzwP/HvnIB2aWCpwL/G8ca6pKX+Cguz9+pMHd33X3oGo2s97A74Gr3P2j423j7nOBhcB/xLK2RKGAqpmFwPmR7vv/mNn34l1QNcwBfmBm9Sj5z/7tONdzPNWq0cwuAC4ANsWwtmNV6z3g7oeAd4FLYlpdFdz9K+AdSiZvhpLe03Me9vDejsCqeBdRhbrAS8C17r6+im1XE9j7IhQKqBpw9yLgckrmDCwE5prZyLgWVQV3XwukUtIzeTW+1RxfNWq8wcxyKelZ3Rb5IxsXJ/gesFjVdYLKnuYL+vReAjkI/BMYVY1tQ31fxF2wc/Elish/xkuBpWb2HjACeDKeNVXDy8AUSq7hNI1vKRWqrMa5x04uHE8VvAeOEllmphOwLrbVVct8YKqZdQHOcvfQeycfAMPiXUQVDgPDgcVmdp+7T6pk28uAnNiUlVjUg6oBM7vYzNqVaUoHPq1o+4D8Efhvd38v3oVUIhFqrNZ7wMySgV8DmyO9w6BEeoFLKPmZJ0Lv6e9A3ciKBwCYWZqZXRHHmspx9z2UXEu90cyO25Mys+uBgSTGzz3m1IOqmYbAjMjw4WJKroWMrnyX+HP3AkpGFgUrEWqMqOg98DzwFzPbT8n1iEWEve7Zs5SMjDt2RF9w3N3NbCgwzczuAfYB+cD4uBZ2HO7+lZkNBt40s8JI851m9v+ABsD7QD93L6zwSeLnLDMrKHP/UXd/NJYFaKojEREJkk7xiYhIkBRQIiISJAWUiIgESQElIiJBUkCJiEiQFFAiUWZmhyKzV79vZv/fzM46wf3Hn+g+IqcDBZRI9O2NzF7dETgA/Gd1d4zMQDEeUEBJraOAEomt/wUuAjCzlyJrGX1wzKwIRWb2iJm9C/wXJbOLL4ms3XSzmU0rs+2tZjY11i9CJBb0QV2RKDOzIndvaGZJwDzgdXefaWZNIjMN1AdWAt9z9+1m5sAN7v5cZP98IMPdt5lZQyKzorv7QTP7JyUT5gY9JZTIydBURyLRVz8y+zqU9KBmRW7fEZmyB+B8oB2wHThESZCV4+5FZvZ34CozWwckK5zkdKWAEom+vZEVgEuZWR9KVt/t6e57zGwpUC/y8L7IDOkV+QNwH7Ae+NOpL1ckDAookfhoDOyIhNMlQI9Ktv0GaARsA3D3t83sfKALJQs6ipyWNEhCJD5eB5Iip+kmAysq2TYbeN3MlpRpew5Y7u47olijSFxpkIRIAjKzBcBUd18c71pEokU9KJEEYmbfNrMNlFzXUjjJaU09KBERCZJ6UCIiEiQFlIiIBEkBJSIiQVJAiYhIkBRQIiISpP8DUo080Hn3+B0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rects1 = plt.bar(index, voteResults2018, bar_width,\n",
    "alpha=opacity,\n",
    "color='b',\n",
    "label='Vote results 2018')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, speeches_in_procent2018, bar_width,\n",
    "alpha=opacity,\n",
    "color='g',\n",
    "label='Speeches 2018')\n",
    "\n",
    "plt.xlabel('Party')\n",
    "plt.ylabel('%')\n",
    "plt.title('')\n",
    "plt.xticks(index + bar_width, partyList)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr of total speeches 2017-2018:  12343\n",
      "Nr of total speeches 2018-2019:  9288\n"
     ]
    }
   ],
   "source": [
    "print(\"Nr of total speeches 2017-2018: \", speeches_201718.shape[0])\n",
    "print(\"Nr of total speeches 2018-2019: \", speeches_201819.shape[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots above, we can see that the number speeches correlates with the mandates for the different parties. Some parties have an higher amount of speeches in comparsion to their mandates, indicating an higher frequency of speeches per mandate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now ready to train and evaluate a classifier. More specifically, we ask you to train a [Multinomial Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes) classifier. You will have to\n",
    "\n",
    "1. vectorize the speeches in the training data\n",
    "2. instantiate and fit the Naive Bayes model\n",
    "3. evaluate the model on the test data\n",
    "\n",
    "The scikit-learn library provides a convenience class [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) that allows you to solve the first two tasks with very compact code. For the evaluation you can use the function [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html), which will report per-class precision, recall and F1, as well as overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.63      0.04      0.07       671\n",
      "          KD       0.70      0.02      0.03       821\n",
      "           L       0.92      0.02      0.04       560\n",
      "           M       0.36      0.68      0.47      1644\n",
      "          MP       0.36      0.25      0.29       809\n",
      "           S       0.46      0.84      0.59      2773\n",
      "          SD       0.57      0.12      0.20      1060\n",
      "           V       0.59      0.15      0.24       950\n",
      "\n",
      "    accuracy                           0.43      9288\n",
      "   macro avg       0.57      0.26      0.24      9288\n",
      "weighted avg       0.52      0.43      0.34      9288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write code here to train and evaluate a Multinomial Naive Bayes classifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('countVectorizer', CountVectorizer()),\n",
    "    ('MNB', MultinomialNB())\n",
    "])\n",
    "\n",
    "pipe.fit(training_data['words'], training_data['party'])\n",
    "preds = pipe.predict(test_data['words'])\n",
    "print(classification_report(test_data['party'], preds, target_names=parties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you have expected the results that you got?\n",
    "Answer: No, we are surprised that this simple model yields moderate accuracy (in some cases). However, we were expecting that the f1-score would be higher for those partiew with more speeches.\n",
    "\n",
    "The model performs best on the parties with the most speeches and worst on the parties with the least.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation metrics such as accuracy should not be understood as absolute measures of performance, but should be used only to compare different classifiers. When other classifiers are not available, a simple baseline for text classification is **Most Frequent Class (MFC)**. One way to think of this baseline is as a classifier that, for every document, predicts that class which appears most often in the training data.\n",
    "\n",
    "Determine the most frequent class in the 2017/2018 data. What is the accuracy of the MFC baseline on the test data? Given this baseline accuracy, how do you assess the results of the Naive Bayes classifier from Problem&nbsp;2? Answer with a short text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.00      0.00      0.00       671\n",
      "          KD       0.00      0.00      0.00       821\n",
      "           L       0.00      0.00      0.00       560\n",
      "           M       0.00      0.00      0.00      1644\n",
      "          MP       0.00      0.00      0.00       809\n",
      "           S       0.30      1.00      0.46      2773\n",
      "          SD       0.00      0.00      0.00      1060\n",
      "           V       0.00      0.00      0.00       950\n",
      "\n",
      "    accuracy                           0.30      9288\n",
      "   macro avg       0.04      0.12      0.06      9288\n",
      "weighted avg       0.09      0.30      0.14      9288\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/courses/TDDE16/labs/environment/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write code here to print the baseline accuracy\n",
    "preds = ['S'] * test_data.shape[0]\n",
    "print(classification_report(test_data['party'], preds, target_names=parties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Naive Bayes classifier has higher accuracy (0.43) than the greedy MFC classification approach (0.30). Therefore it is sufficient to use the Naive Bayes classifier approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Creating a balanced data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you saw in Problem&nbsp;1, the distribution of the speeches over the eight different parties (classes) is imbalanced. One technique used to alleviate this is **undersampling**, in which one randomly removes samples from over-represented classes until all classes are represented with the same number of samples.\n",
    "\n",
    "Implement undersampling to create a balanced subset of the training data. Rerun the evaluation from Problem&nbsp;2 on the balanced data and compare the results. Discuss your findings in a short text. Would you argue that undersampling make sense for the task of predicting the party of a speaker?\n",
    "\n",
    "**Hint:** Your balanced subset should consist of 5,752 speeches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MP    719\n",
      "L     719\n",
      "KD    719\n",
      "S     719\n",
      "M     719\n",
      "C     719\n",
      "SD    719\n",
      "V     719\n",
      "Name: party, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write code here to implement undersampling\n",
    "training_undersampled = pd.DataFrame(columns = ['id', 'words', 'party'])\n",
    "for party in parties:\n",
    "    training_undersampled = training_undersampled.append(training_data[training_data['party'] == party][:719], ignore_index=True)\n",
    "\n",
    "classes = training_undersampled[\"party\"].value_counts()\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           C       0.24      0.44      0.31       671\n",
      "          KD       0.26      0.40      0.32       821\n",
      "           L       0.23      0.47      0.31       560\n",
      "           M       0.39      0.39      0.39      1644\n",
      "          MP       0.35      0.34      0.35       809\n",
      "           S       0.80      0.23      0.35      2773\n",
      "          SD       0.44      0.40      0.42      1060\n",
      "           V       0.37      0.57      0.45       950\n",
      "\n",
      "    accuracy                           0.37      9288\n",
      "   macro avg       0.39      0.41      0.36      9288\n",
      "weighted avg       0.48      0.37      0.37      9288\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(training_undersampled['words'], training_undersampled['party'])\n",
    "preds = pipe.predict(test_data['words'])\n",
    "print(classification_report(test_data['party'], preds, target_names=parties))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fitting the model with the undersampled training set, we get lower accuracy, but a more even f1-score across all parties. When using undersampling we will create a more general model, that will give more general predictions. \n",
    "\n",
    "S and M was overrepresented in both the train and test set, making the model \"weighted\" towards S and M, and therefore often predicting one of the two. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **confusion matrix** is a specific table layout that is useful when analysing the performance of a classifier. In this matrix, both the rows and the columns correspond to classes, and each cell $(i, j)$ states how many times a sample with gold-standard class $i$ was predicted as belonging to class $j$.\n",
    "\n",
    "In scitkit-learn, the confusion matrix of a classifier is computed by the function [`confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html).\n",
    "\n",
    "Your task is to use the confusion matrix to find, for each given party $p$ in the Riksdag, that other party $p'$ which the classifier that you trained in Problem&nbsp;4 most often confuses $p$ with when it predicts the party of a speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[295  75  64  97  36   4  41  59]\n",
      " [ 93 330  62 151  36  22  48  79]\n",
      " [ 61  50 263  56  24   6  34  66]\n",
      " [250 225 196 638  72  39 126  98]\n",
      " [ 97  74  84  75 279  58  45  97]\n",
      " [248 315 264 414 306 632 190 404]\n",
      " [111 119 143 121  22  10 426 108]\n",
      " [ 74  73  60 105  21  17  59 541]] \n",
      "\n",
      "C \t most confused with: \t M \t Occured  97 \t times!\n",
      "KD \t most confused with: \t M \t Occured  151 \t times!\n",
      "L \t most confused with: \t V \t Occured  66 \t times!\n",
      "M \t most confused with: \t C \t Occured  250 \t times!\n",
      "MP \t most confused with: \t C \t Occured  97 \t times!\n",
      "S \t most confused with: \t M \t Occured  414 \t times!\n",
      "SD \t most confused with: \t L \t Occured  143 \t times!\n",
      "V \t most confused with: \t M \t Occured  105 \t times!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write code here to solve Problem 5\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "cm = confusion_matrix(test_data['party'], preds, labels=parties)\n",
    "print(cm, \"\\n\")\n",
    "\n",
    "for index, party in enumerate(parties):\n",
    "    maxVal = 0\n",
    "    indexMax = 0\n",
    "    for i, x in enumerate(cm[index]):\n",
    "        if (i != index):\n",
    "            if maxVal < x:\n",
    "                maxVal = x\n",
    "                indexMax = i\n",
    "    print(party, \"\\t most confused with: \\t\", parties[indexMax], \"\\t Occured \", cm[index][indexMax], \"\\t times!\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6: Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, you have been using the vectorizer and the Naive Bayes classifier with their default hyperparameters. When working with real-world applications, you would want to find settings for the hyperparameters that maximize the performance for the task at hand.\n",
    "\n",
    "Manually tweaking the hyperparameters of the various components of a vectorizer–classifier pipeline can be cumbersome. However, scikit-learn makes it possible to run an exhaustive search for the best hyperparameters over a grid of possible values. This method is known as **grid search**.\n",
    "\n",
    "The hyperparameters of a pipeline should never be tuned on the final test set. (Why would that be a bad idea?) Instead, one should either use a separate validation set, or run cross-validation over different folds. Here we will use cross-validation.\n",
    "\n",
    "Implement a grid search with 5-fold cross-validation to find the optimal parameters in a grid defined by the following choices for the hyperparameters:\n",
    "\n",
    "* In the vectorizer, try a set-of-words model instead of the default bag-of-words model (two possible parameter values).\n",
    "* Also in the vectorizer, try extracting $n$-grams up to $n = 2$ (two possible parameter values).\n",
    "* In the Naive Bayes classifier, try using additive smoothing with $\\alpha \\in \\{1, 0{.}1\\}$ (two possible parameter values).\n",
    "\n",
    "Use the class [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) from the scikit-learn library. Print the results of your best model, along with the parameter values that yielded these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('countVectorizer',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accen...\n",
       "                                                        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                        tokenizer=None,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('MNB',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'MNB__alpha': [1, 0.1],\n",
       "                         'countVectorizer__binary': ['True', 'False'],\n",
       "                         'countVectorizer__ngram_range': [(1, 1), (1, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Write code here to implement the grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {'countVectorizer__binary':['True', 'False'], \n",
    "        'countVectorizer__ngram_range':[(1,1),(1,2)], \n",
    "        'MNB__alpha':[1,0.1] }\n",
    "gridObj = GridSearchCV(pipe, params, cv=5)\n",
    "gridObj.fit(training_undersampled['words'], training_undersampled['party'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.542):\n",
      "{'MNB__alpha': 0.1, 'countVectorizer__binary': 'True', 'countVectorizer__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameter (CV score=%0.3f):\" % gridObj.best_score_)\n",
    "print(gridObj.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6: Try to improve your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn makes it easy to test different vectorizer–classifier pipelines – among other things, it includes different types of logistic regression classifiers, support vector machines, and decision trees. Browse the library to see which methods are supported.\n",
    "\n",
    "Build a pipeline that you find interesting, and use grid search to find optimal settings for the hyperparameters. Print the results of your best model. Did you manage to get better results than the ones that you obtained in Problem&nbsp;5? Answer with a short text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('TFIDF',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_word...\n",
       "                                                  intercept_scaling=1,\n",
       "                                                  loss='squared_hinge',\n",
       "                                                  max_iter=1000,\n",
       "                                                  multi_class='ovr',\n",
       "                                                  penalty='l2',\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'LSVC__tol': [1e-05, 0.0001],\n",
       "                         'TFIDF__binary': ['True', 'False'],\n",
       "                         'TFIDF__ngram_range': [(1, 1), (1, 2)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Write code here to search for a better model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipe1 = Pipeline([\n",
    "    ('TFIDF', TfidfVectorizer()),\n",
    "    ('LSVC', LinearSVC())\n",
    "])\n",
    "\n",
    "params = { \n",
    "        'TFIDF__binary':['True', 'False'], \n",
    "        'TFIDF__ngram_range':[(1,1),(1,2)],\n",
    "        'LSVC__tol':[1e-5, 1e-4]\n",
    "}\n",
    "gridObj = GridSearchCV(pipe1, params, cv=5)\n",
    "gridObj.fit(training_undersampled['words'], training_undersampled['party'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.598):\n",
      "{'LSVC__tol': 1e-05, 'TFIDF__binary': 'True', 'TFIDF__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameter (CV score=%0.3f):\" % gridObj.best_score_)\n",
    "print(gridObj.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to obtain a slightly better R2-score (0.598 compared to 0.542) when using a pipeline consisting of a TFIDF vectorizer and a Linear Support Vector Classifier when optimizing the hyperparameters. This means that our model generally fits the data better that the model in problem five. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    Please read the section ‘General information’ on the ‘Labs’ page of the course website before submitting this notebook!\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
